{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2655f5a7",
      "metadata": {},
      "source": [
        "# Homework: Search Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "84fb77fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: minsearch 0.0.4\n",
            "Uninstalling minsearch-0.0.4:\n",
            "  Successfully uninstalled minsearch-0.0.4\n",
            "Collecting minsearch\n",
            "  Using cached minsearch-0.0.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: qdrant_client in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (1.15.0)\n",
            "Requirement already satisfied: numpy in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (1.24.4)\n",
            "Requirement already satisfied: pandas in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (1.6.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.10.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.11.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.5.0)\n",
            "Requirement already satisfied: anyio in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
            "Using cached minsearch-0.0.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: minsearch\n",
            "Successfully installed minsearch-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall minsearch -y\n",
        "!pip install -U minsearch qdrant_client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51ccbc36",
      "metadata": {},
      "source": [
        "### Evaluation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd36b338",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/selamsew/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/selamsew/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
        "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
        "documents = requests.get(docs_url).json()\n",
        "\n",
        "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
        "df_ground_truth = pd.read_csv(ground_truth_url)\n",
        "ground_truth = df_ground_truth.to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff85174f",
      "metadata": {},
      "source": [
        "Here, `documents` contains the documents from the FAQ database with unique IDs, and `ground_truth` contains generated question-answer pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddf350e1",
      "metadata": {},
      "source": [
        "### we will need the following code for evaluating retrieval: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "04188666",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Measures if at least one relevant document is found in the top k results.\n",
        "def hit_rate(relevance_total):\n",
        "    cnt = 0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        if True in line:\n",
        "            cnt = cnt + 1\n",
        "\n",
        "    return cnt / len(relevance_total)\n",
        "\n",
        "#  Average rank of the first relevant document across queries.\n",
        "def mrr(relevance_total):\n",
        "    total_score = 0.0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        for rank in range(len(line)):\n",
        "            if line[rank] == True:\n",
        "                total_score = total_score + 1 / (rank + 1)\n",
        "\n",
        "    return total_score / len(relevance_total)\n",
        "\n",
        "def evaluate(ground_truth, search_function):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']\n",
        "        results = search_function(q)\n",
        "        relevance = [d['id'] == doc_id for d in results]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0745878",
      "metadata": {},
      "source": [
        "### Q1. Minsearch text\n",
        "\n",
        "Now let's evaluate our usual minsearch approach, but tweak the parameters. Let's use the following boosting params:\n",
        "\n",
        "```python\n",
        " boost = {'question': 1.5, 'section': 0.1} \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "65e4c069",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<minsearch.minsearch.Index at 0x7f88a103d820>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from minsearch import Index\n",
        "\n",
        "boost = {'question': 1.5, 'section': 0.1}\n",
        "\n",
        "# initalize our index\n",
        "index = Index(\n",
        "    text_fields=['question', 'text', 'section'],\n",
        "    keyword_fields=[]\n",
        ")\n",
        "index.fit(documents) # making out document indexable \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2dd3a17c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total queries: 4627\n",
            "Example query: {'question': 'When does the course begin?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total queries: {len(ground_truth)}\")\n",
        "print(\"Example query:\", ground_truth[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ff9007ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# search function for a certain query\n",
        "\n",
        "def search_function(q):\n",
        "    return index.search(\n",
        "        query=q['question'],\n",
        "        filter_dict=None,\n",
        "        boost_dict=boost,\n",
        "        num_results=10\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d130e58e",
      "metadata": {},
      "source": [
        "### Now we will feed each question from `ground_truth` to our `search_function` (minsearch), then we will compare the result from the search to the ground_truth answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "284a8f90",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbf03cc936564351a52eb6a29740e108",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hit_rate': 0.8597363302355738, 'mrr': 0.6897542375497872}\n"
          ]
        }
      ],
      "source": [
        "metrics = evaluate(ground_truth, search_function)\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c02e40",
      "metadata": {},
      "source": [
        "# `Q1-Answer -> 0.85 and the closer answer is 0.84` "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d15dfa6",
      "metadata": {},
      "source": [
        "### Embeddings\n",
        "\n",
        "The latest version of minsearch also supports vector search. We will use it:\n",
        "\n",
        "\n",
        "We will also use `TF-IDF (Term Frequency – Inverse Document Frequency)` and Singular Value Decomposition to create embeddings from texts.\n",
        "\n",
        "#### What TF-IDF Does:\n",
        "\n",
        "It looks at word appearance patterns across the documents.\n",
        "\n",
        "It gives more weight to:\n",
        "\n",
        "- Words that appear frequently in a specific document (high term frequency),\n",
        "\n",
        "- But less frequently across all documents (high inverse document frequency)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed04b510",
      "metadata": {},
      "outputs": [],
      "source": [
        "from minsearch import VectorSearch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3485e329",
      "metadata": {},
      "source": [
        "#### Let's create embeddings for the \"question\" field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ba0f8ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = []\n",
        "\n",
        "for doc in documents:\n",
        "    t = doc['question']\n",
        "    texts.append(t)\n",
        "    \n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(min_df=3), # Only keep words that appear in at least 3 questions (removes noise/rare words).\n",
        "    \n",
        "    # we use random_state for repeatable results (for testing, debugging, or sharing).\n",
        "    TruncatedSVD(n_components=128, random_state=1) # 128 dimensions, and Hey computer, random_state use the same random choices every time\n",
        ")\n",
        "\n",
        "# Creates a reusable pipeline\n",
        "X = pipeline.fit_transform(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e08a10d",
      "metadata": {},
      "source": [
        "### Q2. Vector search for question\n",
        "\n",
        "Now let's index these embeddings with minsearch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "27d583d4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<minsearch.vector.VectorSearch at 0x7f88a12d39a0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vindex = VectorSearch(keyword_fields={'course'})\n",
        "vindex.fit(X, documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee83053",
      "metadata": {},
      "source": [
        "#### create the `search_function`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "309e241a",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def search_function(q):\n",
        "    query_vec = pipeline.transform([q['question']])\n",
        "    return vindex.search(query_vec, filter_dict=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0cf588",
      "metadata": {},
      "source": [
        "#### Now let's evaluate "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1256df5f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc2347fc6f524a0cb1da3896361f8fd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hit_rate': 0.4696347525394424, 'mrr': 0.30031389257669755}\n"
          ]
        }
      ],
      "source": [
        "metrics = evaluate(ground_truth, search_function)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f19a58d8",
      "metadata": {},
      "source": [
        "# `Q2-Answer -> mrr': 0.3, so close one is 0.35`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e6f61f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "37cdd02e",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
