{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2655f5a7",
      "metadata": {},
      "source": [
        "# Homework: Search Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "84fb77fe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping minsearch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting minsearch\n",
            "  Using cached minsearch-0.0.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: qdrant_client in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (1.15.0)\n",
            "Requirement already satisfied: numpy in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (1.24.4)\n",
            "Requirement already satisfied: pandas in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from minsearch) (1.6.1)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.10.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.11.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from qdrant_client) (2.5.0)\n",
            "Requirement already satisfied: anyio in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
            "Requirement already satisfied: idna in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from pandas->minsearch) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/selamsew/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->minsearch) (3.6.0)\n",
            "Using cached minsearch-0.0.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: minsearch\n",
            "Successfully installed minsearch-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall minsearch -y\n",
        "!pip install -U minsearch qdrant_client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51ccbc36",
      "metadata": {},
      "source": [
        "### Evaluation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dd36b338",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
        "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
        "documents = requests.get(docs_url).json()\n",
        "\n",
        "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
        "df_ground_truth = pd.read_csv(ground_truth_url)\n",
        "ground_truth = df_ground_truth.to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff85174f",
      "metadata": {},
      "source": [
        "Here, `documents` contains the documents from the FAQ database with unique IDs, and `ground_truth` contains generated question-answer pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddf350e1",
      "metadata": {},
      "source": [
        "### we will need the following code for evaluating retrieval: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "04188666",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Measures if at least one relevant document is found in the top k results.\n",
        "def hit_rate(relevance_total):\n",
        "    cnt = 0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        if True in line:\n",
        "            cnt = cnt + 1\n",
        "\n",
        "    return cnt / len(relevance_total)\n",
        "\n",
        "#  Average rank of the first relevant document across queries.\n",
        "def mrr(relevance_total):\n",
        "    total_score = 0.0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        for rank in range(len(line)):\n",
        "            if line[rank] == True:\n",
        "                total_score = total_score + 1 / (rank + 1)\n",
        "\n",
        "    return total_score / len(relevance_total)\n",
        "\n",
        "def evaluate(ground_truth, search_function):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']\n",
        "        results = search_function(q)\n",
        "        relevance = [d['id'] == doc_id for d in results]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0745878",
      "metadata": {},
      "source": [
        "### Q1. Minsearch text\n",
        "\n",
        "Now let's evaluate our usual minsearch approach, but tweak the parameters. Let's use the following boosting params:\n",
        "\n",
        "```python\n",
        " boost = {'question': 1.5, 'section': 0.1} \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "65e4c069",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<minsearch.minsearch.Index at 0x7f978e4057c0>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from minsearch import Index\n",
        "\n",
        "boost = {'question': 1.5, 'section': 0.1}\n",
        "\n",
        "# initalize our index\n",
        "index = Index(\n",
        "    text_fields=['question', 'text', 'section'],\n",
        "    keyword_fields=[]\n",
        ")\n",
        "index.fit(documents) # making out document indexable \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2dd3a17c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total queries: 4627\n",
            "Example query: {'question': 'When does the course begin?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total queries: {len(ground_truth)}\")\n",
        "print(\"Example query:\", ground_truth[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ff9007ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# search function for a certain query\n",
        "\n",
        "def search_function(q):\n",
        "    return index.search(\n",
        "        query=q['question'],\n",
        "        filter_dict=None,\n",
        "        boost_dict=boost,\n",
        "        num_results=10\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d130e58e",
      "metadata": {},
      "source": [
        "### Now we will feed each question from `ground_truth` to our `search_function` (minsearch), then we will compare the result from the search to the ground_truth answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "284a8f90",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1545ab6685640afa08455f4c9190af7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'hit_rate': 0.8597363302355738, 'mrr': 0.6897542375497872}\n"
          ]
        }
      ],
      "source": [
        "metrics = evaluate(ground_truth, search_function)\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4c02e40",
      "metadata": {},
      "source": [
        "# `Q1-Answer -> 0.85 and the closer answer is 0.84` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c967c164",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
