{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adea8094",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21a7eb1b",
      "metadata": {},
      "source": [
        "Guidelines for Prompting\n",
        "\n",
        "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8c8c7751",
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee9db7df",
      "metadata": {},
      "source": [
        "#### Helper function  `get_completion`\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "76f33a82",
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "client = openai.OpenAI()  # Make sure you initialized the client\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eab63f6",
      "metadata": {},
      "source": [
        "Note: This and all other lab notebooks of this course use OpenAI library version 0.27.0.\n",
        "\n",
        "In order to use the OpenAI library version 1.0.0, here is the code that you would use instead for the get_completion function:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab32b4a",
      "metadata": {},
      "source": [
        "**Note:** This and all other lab notebooks of this course use OpenAI library version `0.27.0`. \n",
        "\n",
        "In order to use the OpenAI library version `1.0.0`, here is the code that you would use instead for the `get_completion` function:\n",
        "\n",
        "```python\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5ee28e",
      "metadata": {},
      "source": [
        "#### Prompting Principles\n",
        "\n",
        "- **Principle 1: Write clear and specific instructions**\n",
        "- **Principle 2: Give the model time to “think”**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579f1db5",
      "metadata": {},
      "source": [
        "### Tactics for principle 1\n",
        "\n",
        "##### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "> Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`\n",
        "\n",
        "##### Tactic 2: Ask for a structured output\n",
        "- JSON, HTML\n",
        "##### Tactic 3: Ask the model to check whether conditions are satisfied\n",
        "- Check assumptions required to do the task\n",
        "##### Tactic 4: \"Few-shot\" prompting\n",
        "- Give successful examples of completing tasks then ask the model to perform the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "54e50554",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is important to provide clear and specific instructions to a model in order to guide it towards the desired output and reduce the chances of receiving irrelevant or incorrect responses, with longer prompts often providing more clarity and context for the model.\n"
          ]
        }
      ],
      "source": [
        "# tactic 1\n",
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\ \n",
        "providing instructions that are as clear and \\ \n",
        "specific as you can possibly make them. \\ \n",
        "This will guide the model towards the desired output, \\ \n",
        "and reduce the chances of receiving irrelevant \\ \n",
        "or incorrect responses. Don't confuse writing a \\ \n",
        "clear prompt with writing a short prompt. \\ \n",
        "In many cases, longer prompts provide more clarity \\ \n",
        "and context for the model, which can lead to \\ \n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\ \n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24bf2bcc",
      "metadata": {},
      "source": [
        "### Tactics for Principle 2: Give the model time to “think” \n",
        "##### Tactic 1: Specify the steps required to complete a task\n",
        "\n",
        "##### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c4ff5ba",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
