{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9882c0cb",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Two types of large language models (LLMs)\n",
    "\n",
    "1. Base LLM\n",
    "2. Instruction Tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f545f",
   "metadata": {},
   "source": [
    "#### Base LLM \n",
    "- Predicts next word, based on text training data.\n",
    "##### Instruction Tuned LLM\n",
    "- Tries to follow instructions\n",
    "- Fine-tune on instructions and good attempts at following those instrucitons.\n",
    "- Uses a technique called `RLHF`: Reinforcement Learning with Human FeedBack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76728747",
   "metadata": {},
   "source": [
    "#### In-Context Learning: Zero-Shot and Few-Shot\n",
    "\n",
    "- Teaching models what to do via prompts is known as `in-context` learning. \n",
    "- Each example provided in the prompt is called a `shot`. \n",
    "- `Teaching a model to learn from examples in the prompt` is also called `few-shot` learning.\n",
    "    - With five examples, it’s 5-shot learning. When `no example is provided`, it’s zero-shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a4124",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "> prompt to refer to the whole input into the model, and context to refer to the information provided to the model so that it can perform a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442a005",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "\n",
    "A `prompt` generally consists of one or more of the following parts:\n",
    "\n",
    "`Task description`\n",
    "\n",
    "What you want the model to do, including the role you want the model to play\n",
    "and the output format.\n",
    "\n",
    "`Example(s) of how to do this task`\n",
    "\n",
    "For example, if you want the model to detect toxicity in text, you might provide a\n",
    "few examples of what toxicity and non-toxicity look like.\n",
    "\n",
    "`The task`\n",
    "\n",
    "The concrete task you want the model to do, such as the question to answer or\n",
    "the book to summarize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77321d0",
   "metadata": {},
   "source": [
    "### System Prompt and User Prompt\n",
    "\n",
    "Many model APIs give you the option to split a prompt into a `system prompt` and a\n",
    "`user prompt`. You can think of the system prompt as the task description and the user\n",
    "prompt as the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13ce22",
   "metadata": {},
   "source": [
    "`System prompt`: You’re an experienced real estate agent. Your job is to\\\n",
    "read each disclosure carefully, fairly assess the condition of the\\\n",
    "property based on this disclosure, and help your buyer understand the\\\n",
    "risks and opportunities of each property. For each question, answer\\\n",
    "succinctly and professionally.\n",
    "\n",
    "`User prompt`:\n",
    "Context: [disclosure.pdf]\n",
    "\n",
    "Question: Summarize the noise complaints, if any, about this property.\n",
    "\n",
    "Answer:\n",
    "\n",
    "\n",
    "\n",
    "**NOTE**\n",
    "> Many model providers emphasize that well-crafted system prompts can improve performance.\n",
    "\n",
    ">System prompt, user prompt, examples, and context are the key components of a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89eb4d",
   "metadata": {},
   "source": [
    "`Temepalates`: is abasically how you structure your prompt for the LLMs to use. And each llm has it own templates \n",
    "\n",
    "**General Advice about templates**  \n",
    "> When constructing inputs for a foundation model, make sure that your inputs follow the model’s chat template exactly.\n",
    "\n",
    "> If you use a third-party tool to construct prompts, verify that this tool uses the correct chat template. Template errors are, unfortunately, very common. These errors are hard to spot because they cause silent failures—the model will do some‐thing reasonable even if the template is wrong.\n",
    "\n",
    "> Before sending a query to a model, print out the final prompt to double-check if it follows the expected template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c393b37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847b3b0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d28e0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
